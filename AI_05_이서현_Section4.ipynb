{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_05_이서현_Section4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGOt5Ii+tlLS1zQKD5+4IE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eeseohyun/project/blob/main/AI_05_%EC%9D%B4%EC%84%9C%ED%98%84_Section4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYY85Ujwkkoo"
      },
      "source": [
        "**필요한 패키지 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey3asWTmjmP9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import glob\n",
        "# xml 파일을 다루기 위한 모듈\n",
        "from xml.etree import ElementTree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_7glmQ8jnKO"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoE2fNjbjpBR"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E2Fe4EWj0k2"
      },
      "source": [
        "dir = '/content/drive/MyDrive/Colab Notebooks/face mask detection'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LBHAMkQj06e"
      },
      "source": [
        "annotations_dir = os.path.join(dir, 'annotations')\n",
        "images_dir = os.path.join(dir, 'images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltiBF_5Rj3ey"
      },
      "source": [
        "annotations_files = os.listdir(annotations_dir)\n",
        "images_files = os.listdir(images_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL0ZkX6Yj7Q9"
      },
      "source": [
        "print('Total annotaions file :', len(annotations_files))\n",
        "print('Total images file :', len(images_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ7mlyYAkpaH"
      },
      "source": [
        "**데이터 추출**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfYUWuq3j-gA"
      },
      "source": [
        "information = {'xmin': [], 'ymin': [], 'xmax': [], 'ymax': [], 'label': [], 'file': [], 'width': [], 'height': []}\n",
        "\n",
        "for annotation in glob.glob(annotations_dir + '/*.xml'):\n",
        "    tree = ElementTree.parse(annotation)\n",
        "    \n",
        "    for element in tree.iter():\n",
        "        if 'size' in element.tag:\n",
        "            for attribute in list(element):\n",
        "                if 'width' in attribute.tag: \n",
        "                    width = int(round(float(attribute.text)))\n",
        "                if 'height' in attribute.tag:\n",
        "                    height = int(round(float(attribute.text)))    \n",
        "        if 'object' in element.tag:\n",
        "            for attribute in list(element):\n",
        "                \n",
        "                if 'name' in attribute.tag:\n",
        "                    name = attribute.text                 \n",
        "                    information['label'] += [name]\n",
        "                    information['width'] += [width]\n",
        "                    information['height'] += [height] \n",
        "                    information['file'] += [annotation.split('/')[-1][0:-4]] \n",
        "                            \n",
        "                if 'bndbox' in attribute.tag:\n",
        "                    for dimension in list(attribute):\n",
        "                        if 'xmin' in dimension.tag:\n",
        "                            xmin = int(round(float(dimension.text)))\n",
        "                            information['xmin'] += [xmin]\n",
        "                        if 'ymin' in dimension.tag:\n",
        "                            ymin = int(round(float(dimension.text)))\n",
        "                            information['ymin'] += [ymin]                                \n",
        "                        if 'xmax' in dimension.tag:\n",
        "                            xmax = int(round(float(dimension.text)))\n",
        "                            information['xmax'] += [xmax]                                \n",
        "                        if 'ymax' in dimension.tag:\n",
        "                            ymax = int(round(float(dimension.text)))\n",
        "                            information['ymax'] += [ymax]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAoFus_kALC"
      },
      "source": [
        "annotations_info_df = pd.DataFrame(information)\n",
        "annotations_info_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc-Ikka7kgz3"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9iMrlektA2"
      },
      "source": [
        "# Annotation&Image에 파일명 추가하기(.xml, .png)\n",
        "annotations_info_df['annotation_file'] = annotations_info_df['file'] + '.xml'\n",
        "annotations_info_df['image_file'] = annotations_info_df['file'] + '.png'\n",
        "\n",
        "# \"mask_weared_incorrect\" 레이블을 \"mask_incorrectly_worn\" 으로 변경\n",
        "annotations_info_df.loc[annotations_info_df['label'] == 'mask_weared_incorrect', 'label'] = 'mask_incorrectly_worn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh1wJIiFkvqF"
      },
      "source": [
        "annotations_info_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x571qP_XkzNM"
      },
      "source": [
        "**Label이 올바른지 확인**\n",
        "```ex> Image_001```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmU_Q1XLk0cX"
      },
      "source": [
        "# 첫번째 라벨 사진으로 결과 확인해보기\n",
        "annotations_info_df['image_file'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBJCp4vVk6wi"
      },
      "source": [
        "# Image 001 File Path\n",
        "image_001_path = os.path.join(images_dir, annotations_info_df['image_file'].iloc[0])\n",
        "image_001_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mL8Lpyok7a-"
      },
      "source": [
        "# Read Image_001\n",
        "image_001 = cv2.imread(image_001_path)\n",
        "image_001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18lF5K2hk_Jy"
      },
      "source": [
        "# 실제 이미지 구현 함수\n",
        "def render_image(image):\n",
        "    plt.figure(figsize = (12, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "# BGR -> RGB로 변환하는 함수\n",
        "def convert_to_RGB(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGRQpaMylA12"
      },
      "source": [
        "# 위의 함수 적용\n",
        "render_image(image_001)\n",
        "render_image(convert_to_RGB(image_001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iGQWoezlEE4"
      },
      "source": [
        "# Shape of Image_001\n",
        "image_001.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-7BMDNtlF9_"
      },
      "source": [
        "# Image_001 Annotation\n",
        "annotation_001_path = os.path.join(annotations_dir, annotations_info_df['annotation_file'].iloc[0])\n",
        "annotation_001_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_INBSxlLlH8j"
      },
      "source": [
        "**이미지 자르기**\n",
        "\n",
        "\n",
        "한 이미지에 여러 개의 라벨 존재(=한 이미지에서 두 명 이상의 사람이 존재)\n",
        "\n",
        "따라서, 한 사람으로만 구성된 여러 개의 이미지로 이미지를 잘라내도록 한다. \n",
        "\n",
        "경계 상자 내에서 이미지를 자르도록 ```xmin, ymin, xmax, ymax 값```을 정의해줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xNaFinjlIpm"
      },
      "source": [
        "# Image_001을 예시로 듬\n",
        "x = annotations_info_df['xmin'].iloc[0]\n",
        "y = annotations_info_df['ymin'].iloc[0]\n",
        "width = annotations_info_df['xmax'].iloc[0]\n",
        "height = annotations_info_df['ymax'].iloc[0]\n",
        "\n",
        "cropped_001 = image_001[y:height, x:width]\n",
        "render_image(cropped_001)\n",
        "\n",
        "# 함수 적용\n",
        "render_image(convert_to_RGB(cropped_001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgdpxt30lexe"
      },
      "source": [
        "**자른 이미지에 대한 새로운 디렉토리 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EK8v0xxlfmG"
      },
      "source": [
        "# 자른 이미지 폴더 생성\n",
        "directory = 'cropped_images'\n",
        "parent_directory = dir\n",
        "path = os.path.join(parent_directory, directory)\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRwf-S1rliio"
      },
      "source": [
        "# 파일 이름 복사(.png 확장자로 추가하기 전)\n",
        "annotations_info_df['cropped_image_file'] = annotations_info_df['file']\n",
        "annotations_info_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9k99ba4llBO"
      },
      "source": [
        "for i in range(len(annotations_info_df)):\n",
        "    # 파일 경로 가져오기 & 이미지 읽기\n",
        "    image_filepath = os.path.join(images_dir + '/' + annotations_info_df['image_file'].iloc[i])\n",
        "    image = cv2.imread(image_filepath)\n",
        "    \n",
        "    # 잘라낸 이미지 파일 이름 설정 'file-i.png'\n",
        "    annotations_info_df['cropped_image_file'].iloc[i] = annotations_info_df['cropped_image_file'].iloc[i] + '-' + str(i) + '.png'\n",
        "    cropped_image_filename = annotations_info_df['cropped_image_file'].iloc[i]\n",
        "    \n",
        "    # 이미지를 자르기 위한 xmin, ymin, xmax, ymax 값 설정\n",
        "    xmin = annotations_info_df['xmin'].iloc[i]\n",
        "    ymin = annotations_info_df['ymin'].iloc[i]\n",
        "    xmax = annotations_info_df['xmax'].iloc[i]\n",
        "    ymax = annotations_info_df['ymax'].iloc[i]\n",
        "\n",
        "    # 설정한 값으로 이미지 자르기 \n",
        "    cropped_image = image[ymin : ymax, xmin : xmax]\n",
        "    \n",
        "    # 잘라낸 이미지 저장하기 cv2.imwrite\n",
        "    cropped_image_directory = os.path.join(path, cropped_image_filename) \n",
        "    cv2.imwrite(cropped_image_directory, cropped_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuLeyWePlq7m"
      },
      "source": [
        "annotations_info_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grW5dUOEm_vh"
      },
      "source": [
        "# 잘린 이미지가 저장되었는지 확인\n",
        "cropped_images_files = os.listdir(path)\n",
        "cropped_images_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNwC757anCQr"
      },
      "source": [
        "print('There are {} cropped images in total.'.format(len(cropped_images_files)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Tf9ZIrnErp"
      },
      "source": [
        "0번 인덱스의 이미지(Image_001)를 다시 가져와서 잘린 이미지를 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0BD2iOpnCs1"
      },
      "source": [
        "# Image_001 File Name\n",
        "annotations_info_df['cropped_image_file'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VURiiC_XnG7Z"
      },
      "source": [
        "# Image_001 File Path\n",
        "cropped_001_0_path = os.path.join(path, annotations_info_df['cropped_image_file'].iloc[0])\n",
        "cropped_001_0_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6WDxhnVnIq3"
      },
      "source": [
        "# Read Image_001\n",
        "cropped_001_0 = cv2.imread(cropped_001_0_path)\n",
        "cropped_001_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpkW0H6DnKtl"
      },
      "source": [
        "# 함수 적용\n",
        "render_image(convert_to_RGB(cropped_001_0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3XWXSrDnMS4"
      },
      "source": [
        "# Shape of Cropped Image_001\n",
        "cropped_001_0.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACqMfpi6nOYN"
      },
      "source": [
        "**훈련/테스트 데이터 나누기**\n",
        "*   테스트 데이터 : 25% \n",
        "*   훈련 데이터 : 75%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnutwSZQnNxJ"
      },
      "source": [
        "test_df = annotations_info_df[:800]\n",
        "train_df = annotations_info_df[800:]\n",
        "\n",
        "\n",
        "train_df.shape, test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE0ylWU5nk1c"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBfOQIW1noZB"
      },
      "source": [
        "# 클래스 분류\n",
        "classes = list(train_df['label'].unique())\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYHHyn5io2sz"
      },
      "source": [
        "**Exploratory Data Analysis (EDA)**\n",
        "\n",
        "*   마스크를 잘 착용하였는가?\n",
        "*   마스크를 착용하지 않았는가?\n",
        "*   마스크를 잘못 착용하였는가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg4e0wHQpUc7"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmxhnJxO2eA-"
      },
      "source": [
        "train_df[train_df['file'] == 'maksssksksss139']['label'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngya9A2_2ngf"
      },
      "source": [
        "image_139_path = os.path.join(images_dir, 'maksssksksss139.png')\n",
        "image_139 = cv2.imread(image_139_path)\n",
        "image_139"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTbF8yOT24d2"
      },
      "source": [
        "# 함수 적용\n",
        "image_139_rgb = convert_to_RGB(image_139)\n",
        "render_image(image_139_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckqlcKHR2_n2"
      },
      "source": [
        "image_139_df = train_df[train_df['file'] == 'maksssksksss139']\n",
        "image_139_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWI0Nogz3EVm"
      },
      "source": [
        "with_mask_list, without_mask_list, incorrectly_worn_list = [], [], []\n",
        "for i in range(len(image_139_df)):\n",
        "    bounding_box = [image_139_df['xmin'].iloc[i], image_139_df['ymin'].iloc[i],\n",
        "                    image_139_df['xmax'].iloc[i], image_139_df['ymax'].iloc[i]]\n",
        "    if image_139_df['label'].iloc[i] == 'with_mask':\n",
        "        with_mask_list.append(bounding_box)\n",
        "    elif image_139_df['label'].iloc[i] == 'without_mask':\n",
        "        without_mask_list.append(bounding_box)\n",
        "    else:\n",
        "        incorrectly_worn_list.append(bounding_box)\n",
        "        \n",
        "found_objects_dict = {'With Mask': with_mask_list, \n",
        "                      'Without Mask': without_mask_list, \n",
        "                      'Incorrectly Worn': incorrectly_worn_list}\n",
        "found_objects_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJf_fVw03Hzg"
      },
      "source": [
        "for key, value in found_objects_dict.items():\n",
        "    for i in range(len(value)):\n",
        "        color = (0, 255, 0) # green\n",
        "        text = 'Mask'\n",
        "        if key == 'Without Mask':\n",
        "            color = (255, 0, 0) # red\n",
        "            text = 'No Mask'\n",
        "        elif key == 'Incorrectly Worn':\n",
        "            color = (255, 255, 0) # yellow\n",
        "            text = 'Incorrect'\n",
        "        start_point = (value[i][0], value[i][1])\n",
        "        end_point = (value[i][2], value[i][3])\n",
        "        cv2.rectangle(image_139_rgb, start_point, end_point, color = color, thickness = 2)\n",
        "        cv2.putText(image_139_rgb, org = (value[i][0] - 8, value[i][1] - 3), text = text, \n",
        "                    fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.5, color = color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccJPxpQ3MLN"
      },
      "source": [
        "render_image(image_139_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUOrCGnL3QCE"
      },
      "source": [
        "# 라벨 별 수\n",
        "train_df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEOu3PrM3Skh"
      },
      "source": [
        "sorted_label_df = pd.DataFrame(train_df['label'].value_counts()).reset_index()\n",
        "sorted_label_df.rename(columns = {'index': 'label', 'label': 'count'}, inplace = True)\n",
        "sorted_label_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yRl-8Pl3dFr"
      },
      "source": [
        "# 시각화\n",
        "plt.style.use('seaborn')\n",
        "plt.figure(figsize = (8, 6))\n",
        "barplot = sns.barplot(x = 'count', y = 'label', data = sorted_label_df, orient = 'horizontal', \n",
        "                      palette = ['skyblue', 'red', 'yellow'])\n",
        "plt.title('Distribution of Labels', fontsize = 20, fontweight = 'bold')\n",
        "plt.xlabel('Count', fontsize = 15, fontweight = 'bold')\n",
        "plt.ylabel('Label', fontsize = 15, fontweight = 'bold')\n",
        "\n",
        "for p in barplot.patches:\n",
        "    width = p.get_width()\n",
        "    percentage = round(width * 100 / sum(sorted_label_df['count']), 2)\n",
        "    plt.text(x = width + 15, y = p.get_y() + 0.55 * p.get_height(), s = f'{int(width)}\\n({percentage} %)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBnERSHi3po9"
      },
      "source": [
        "cropped_image_path = os.path.join(path, train_df['cropped_image_file'].iloc[0])\n",
        "cropped_image = cv2.imread(cropped_image_path)\n",
        "cropped_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmrY341m4q5P"
      },
      "source": [
        "image_width = []\n",
        "image_height = []\n",
        "for i in range(len(train_df)):\n",
        "    cropped_image_path = os.path.join(path, train_df['cropped_image_file'].iloc[i])\n",
        "    cropped_image = cv2.imread(cropped_image_path)\n",
        "    image_width.append(cropped_image.shape[0])\n",
        "    image_height.append(cropped_image.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYSgThaA4_OU"
      },
      "source": [
        "sns.histplot(image_width, kde = True)\n",
        "plt.title('Image Width Distribution', fontsize = 16, fontweight = 'bold')\n",
        "plt.xlabel('Image Width', fontweight = 'bold')\n",
        "plt.ylabel('Count', fontweight = 'bold')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1f1o0ST5C4q"
      },
      "source": [
        "sns.histplot(image_height, kde = True)\n",
        "plt.title('Image Height Distribution', fontsize = 16, fontweight = 'bold')\n",
        "plt.xlabel('Image Height', fontweight = 'bold')\n",
        "plt.ylabel('Count', fontweight = 'bold')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLxMPvoZ5Fpt"
      },
      "source": [
        "print('IMAGE WIDTH')\n",
        "print(f'Min: {min(image_width)}')\n",
        "print(f'Max: {max(image_width)}')\n",
        "print(f'Mean: {np.mean(image_width)}')\n",
        "print(f'Median: {np.median(image_width)}')\n",
        "print('IMAGE HEIGHT')\n",
        "print(f'Min: {min(image_height)}')\n",
        "print(f'Max: {max(image_height)}')\n",
        "print(f'Mean: {np.mean(image_height)}')\n",
        "print(f'Median: {np.median(image_height)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5pVpPTz5Kie"
      },
      "source": [
        "image_target_size = (int(np.median(image_width)), int(np.median(image_height)))\n",
        "image_target_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iQ6ndQ75ORT"
      },
      "source": [
        "**Image Data Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOyXS9xU5LBw"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale = 1. / 255., validation_split = 0.25)\n",
        "\n",
        "train_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    directory = path,\n",
        "    x_col = 'cropped_image_file',\n",
        "    y_col = 'label',\n",
        "    subset = 'training',\n",
        "    batch_size = 32,\n",
        "    seed = 42,\n",
        "    shuffle = True,\n",
        "    class_mode = 'categorical',\n",
        "    target_size = image_target_size\n",
        ")\n",
        "\n",
        "valid_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    directory = path,\n",
        "    x_col = 'cropped_image_file',\n",
        "    y_col = 'label',\n",
        "    subset = 'validation',\n",
        "    batch_size = 32,\n",
        "    seed = 42,\n",
        "    shuffle = True,\n",
        "    class_mode = 'categorical',\n",
        "    target_size = image_target_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-YgBvwL5rCp"
      },
      "source": [
        "test_image_generator = ImageDataGenerator(rescale = 1. / 255.)\n",
        "\n",
        "test_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe = test_df,\n",
        "    directory = path,\n",
        "    x_col = 'cropped_image_file',\n",
        "    y_col = 'label',\n",
        "    batch_size = 32,\n",
        "    seed = 42,\n",
        "    shuffle = True,\n",
        "    class_mode = 'categorical',\n",
        "    target_size = image_target_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoYUe05U5u_v"
      },
      "source": [
        "print(train_generator)\n",
        "print(valid_generator)\n",
        "print(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hsOVUeP5xzb"
      },
      "source": [
        "**Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmbuOa_y5zI2"
      },
      "source": [
        "input_shape = [int(np.median(image_width)), int(np.median(image_height)), 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GnmHlHq51Ot"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu', \n",
        "                        input_shape = input_shape),\n",
        "    keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu'),\n",
        "    keras.layers.MaxPool2D(pool_size = 2, padding = 'valid'),\n",
        "    keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu'),\n",
        "    keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu'),\n",
        "    keras.layers.MaxPool2D(pool_size = 2, padding = 'valid'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units = len(classes), activation = 'softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrcohliW543x"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy', keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(train_generator, epochs = 10, steps_per_epoch = len(train_generator), \n",
        "                        validation_data = valid_generator, validation_steps = len(valid_generator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGSBiVJK6nAj"
      },
      "source": [
        "result = pd.DataFrame(history.history)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUTU0U3861cO"
      },
      "source": [
        "# 시각화\n",
        "result.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}